# Lesson Plan \>

**Lesson ID:** PROG3017-1-2

**Faculty Member:** Sean Morrow

**Subject:** PROG3017 Full Stack Programming

**Content:**

- The Problem with our Workflow

- Docker to the Rescue

- Docker Setup

- Running a Docker Container

- Docker Compose

**Prerequisites:**

- Docker Readme.txt

- Learning Docker by Arthur Ulfeldt (Linkedin Learning)

**Announcements:**

- None required.

## Instructional Procedures:

THE PROBLEM WITH OUR WORKFLOW

- recall developing the quote generator last lesson

	- is a client side web app

	- sent out an AJAX request to a Web API that returns JSON data

- broken down you have:

	- client side web app (JS)

	- has a list of dependencies (webpack, babel, spin.js, etc)

	- needs a server to run on (webpack-dev-server)

	- you have developed this

	- Web API web app (PHP) on public server

	- aka server side web app

	- has a list of dependencies

	- needs a server to run on

	- currently runs on [www.seanmorrow.ca](http://www.seanmorrow.ca)

	- you will develop this

	- database server that contains quote data (MySQL)

	- has service running to receive requests for data from DB

- therefore, the web app is made up of three apps (some you authored
and some not) each with their own dependencies (servers) needed to work

- old workflow with webpack worked fine for only client side
development

- when developing the entire web app you have two web apps you are
developing and three servers that need to be running locally for it to
work -- yikes!

	- three servers need to be installed and configured on machine

	- two web apps will have their usual dependencies that need to be
setup

- what if two developers are working on it?

	- all this configuration needs to be done on both machines

- our old workflow is not going to cut it!

DOCKER TO THE RESCUE

- docker is a tool that breaks up your web app into separate units
called containers (like shipping containers -- hence the name docker)

- each container is a lightweight, standalone, executable package of
software that includes everything needed to run an application: code,
runtime, system tools, system libraries and settings

- in terms of our example -- has three containers:

	- client side container

	- includes all web app dependencies outlined in package.json

	- includes webpack-dev-server to run client side on

	- server side container

	- serves the Web API

	- includes configured apache server to run PHP

	- database container

	- includes configured MySQL database server and required services

- each container encapsulates everything needed for that part of the
web app and are executed to fire up their servers and run it

- a container is created from an image (much like in virtualization)

- Docker is a DevOps tool (set of practices that combines software
development and IT operations)

- container images can be shared on Docker Hub

- docker makes running complex web apps a lot easier without spending
hours configuring servers and installing tools / dependencies

DOCKER SETUP

- docker already installed from previous challenge

- open docker desktop

- docker runs containers on a Linux distro that continually runs as a
service

	- after installation, found in tray of windows

	- can run / stop containers

	- manage images

\[WARNING!! - WINDOWS USERS\]

	- docker engine runs in Linux and our project folder is in windows

	- as a result, the webpack-dev-server watcher won't detect code
changes and refresh the server in that container. The event is not
detected (inotify)

	- easiest solution is develop your web apps in Linux (ubuntu)

	- already installed ubuntu to run on WSL2 in last challenge

	- go to MS Store and install Windows Terminal

	- terminal is a cool app that enables opening any type of installed
shell (git bash / powershell / command prompt / etc.)

	- in terminal, select from dropdown ubuntu

	- point out have terminal access to your ubuntu distro

	- point out this also fires up ubuntu in first place

	- how do you get your project folder into ubuntu?

	- can use github (clone / push)

	- can copy it over in windows explorer

	- open windows explorer and input address and press enter:

```
\\wsl$
```

	- make a shortcut to Ubuntu-22.04/root (is your home directory in
terminal) or it might be Ubuntu-22.04/home/\[username\]

	- copy over your project folders or build new ones here

	- be warned windows might add .Identifier files in your project
folder

	- remove with command in Ubuntu terminal:

```
find . -name "*:Zone.Identifier" -type f -delete
```

- have students install docker extension by microsoft in VSCode

	- start / stop / remove containers and look into their directory
structure

	- can also fire up a shell for any container

	- can build an image by right clicking on a Dockerfile

- open docker extension

RUNNING A DOCKER CONTAINER

- to demonstrate Docker in action, will port over the insult generator

	- for simplicity Web API uses a JSON file instead of DB server

	- will add DB servers in a later lesson

- start by porting server-side Web API from
[www.seanmorrow.ca](http://www.seanmorrow.ca) to a container

	- unchartered territory since we have not done any server-side dev

- first step is to build the container's image which will contain
everything needed for the Web API to run

	- Web API is a PHP script which requires an apache server that can
run it

	- much like client-side we can use commands to set this all up

- demo to students with /quoteGenerator:

	- open project folder in VS Code

	- run command "npm install"

	- create an /api folder and copy over:

getQuotes.php

	- a simple PHP script (covered next semester!)

quotes.json

	- all the quote data

Dockerfile-web-ap

	- the list of commands to build the image

	- NOTE: change name to Dockerfile

	- open Dockerfile in VS Code

	- point out FROM pulls a base container image from Docker Hub that
has apache server included

	- point out for apache servers we use apt-get instead of npm to
install dependencies

	- point out WORKDIR sets up destination directory of /var/www/html
for all files in /api in Container image and COPY copies it over\
	- point out EXPOSE opens up the port 80 on the container

	- when running, containers are stand alone and sandboxed

	- apache runs on port 80 so this sets that port to be exposed for
hitting from *outside* the container

	- build the container image with commands:

```
cd api
docker build -t api-server .
```

	- point out "." at the end is location of Dockerfile

	- point out image is built and displayed in docker panel of VS Code

	- build and run the container from the image with command:

```
docker run -it --name my-api-server -p 80:80 api-server
```

	- the -p option maps the container\'s exposed port 80 to the external
port 80 so it can be used

	- the \--name option defines the container name in docker (random
otherwise)

	- point out container in containers panel of extension

	- point out expanding files to see the container's files

WARNING : if IIS is installed it will have a hold of port 80 --
uninstall it or shut down World Wide Web Publishing Service in windows

	- hit the Web API in browser with <http://localhost/getQuotes.php>

	- open main.js and change QUOTE_API constant:

```
const QUOTE_API = "http://localhost/getQuotes.php";
```

	- open another terminal and run web app with "npm run start"

	- point out web app working with Web API running in a container

	- demo shutting down the container (right click on container in
docker extension and select stop) and hit the Web API again

	- demo removing the container with docker extension and
building/spinning it up again with:

```
docker run -it --name my-api-server -p 80:80 api-server
```

- let's build the client side app's container image

- demo to students with /quoteGenerator:

	- create a folder /client and move everything into it except /api

	- copy Dockerfile-client into /client and rename Dockerfile

	- open Dockerfile in VS Code

	- point out FROM to pull alpine which is a basic node image from
docker hub (includes node and npm)

	- point out setting working directory /usr/app on image and copying
all files from /client

	- point out RUN command to run "npm install"

	- RUN will run the command on the container's image

	- not super efficient as image will be large

	- point out CMD command is much like RUN but runs the command when
the container is up and running

	- npm scripts that run via CMD must be one of a preset (start being
acceptable)

CMD \["npm","start"\] will run "npm run start" command

CMD \["npm", "app"\] will throw an error

	- only one command is allowed with format:

CMD \[\"executable\",\"param1\",\"param2\"\]

	- point out EXPOSE to expose port 3000 which is port
webpack-dev-server runs on as outlined in webpack.config.js

	- need to hit it from outside the container for testing

\[NEED THIS POSSIBLY ON WINDOWS?\]

	- open package.json

	- besides exposing the port, also need to set the IP of the container
to be the wildcard 0.0.0.0 otherwise can't hit webpack-dev-server

	- add option to npm script:

```
"start": "webpack-dev-server --open --host 0.0.0.0",
```

	- build image with commands:

```
cd client
docker build -t client-server .
```

	- open new terminal (if required) and run container with command:

```
docker run -it --name my-client-server -p 3000:3000 client-server
```

	- run web app at http://localhost:3000

	- both containers working with each other!

DOCKER-COMPOSE

- good to know how to manually build a single image and spin up its
container

- with multiple containers this gets cumbersome

- docker-compose is introduced to automatically build and spin up all
the containers of a web app with two easy commands

- also introduces new features like custom networks / volumes

- requires a configuration file (much like a Dockerfile) called
docker-compose.yml and still uses the Dockerfile of each container

	- configs many options previously defined in the docker build / run
commands

- demo to students with /quoteGenerator:

	- shut down all containers and remove all images

	- removing images can be done in docker dashboard (right click docker
icon in tray) and press "Clean Up" button to remove all "unused"
images

	- can also be done by expanding down image and right clicking on
"latest"

	- copy provided docker-compose.yml into root of project folder

	- open docker-compose.yml in VS Code

	- point out client and api container / image names

	- point out client and api exposed ports

	- point out each container image has a volume section

	- entries are \<source\>:\<destination- to define either a bind
mount or volume

	- bind mounts:

	- if \<source- is a path then are defining a bind mount which mounts
a \<source- folder of the host machine to \<destination- folder of
the container

	- bind mount means it is the same folder mounted in the container --
same files

	- point out entire project folder for both client and api are bind
mounted to their containers

	- done so watchers can work

	- code changed means code is changed in container (same code) which
is detected by watchers and force refresh of server

	- volumes:

	- if \<source- is a name then are defining a volume so all files in
\<destination- folder is stored in a volume in a designated folder on
container

	- useful if data needs to persist across container runs and/or be
shared amongst several containers

	- useful for storing DBs so changes made with web app isn't lost when
container restarted, etc.

	- point out in client service /node_modules is given its own volume
so is stored in a volume when created via "npm install" of client
Dockerfile

	- why do this?

	- Container images are built faster and size is smaller due to
node_modules not being inside the container

	- data persists across container runs, so don't need to rebuild giant
node_modules each time

	- to build all container images with command:

```
docker-compose build
```

	- run all containers with command:

```
docker-compose up
```

	- or done with one command:

```
docker-compose up --build
```

	- note unlike previous commands, can be in any folder in project
folder

	- demo working web app with http://localhost/getQuotes.php and

<http://localhost:3000>

	- point out images created / containers running / and single volume
running in docker extension

	- change title of web app in client/html/index.html to demo watchers
working and restarting containers via bind mounts of project folder

- we will use the docker-compose approach for the rest of this course

- containers can be shut down / started / removed via docker extension

	- shut down containers by CTRL+C

	- to remove all containers with "Prune" button in docker panel or
with command:

```
docker-compose down
```

	- to remove all containers and delete their volumes:

```
docker-compose down -v
```

	- useful for killing databases late in course

	- to delete all images with no container associated with it use
command:

```
docker image prune -a
```

- another big advantage of Docker is for deploying release versions of
web apps to AWS (and any other web service)

	- before you would have to configure all the required servers on an
EC2 instance but with docker it is much easier to publish your web app

	- essentially you push your containers to a web service and it runs
the containers there for public access

	- will explore this in a later lesson

**Materials and Equipment**

- /quoteGenerator (PROVIDED)

- /quoteGeneratorDone

- getQuotes.php (PROVIDED)

- quotes.json (PROVIDED)

- Dockerfile-api (PROVIDED)

- Dockerfile-client (PROVIDED)

- docker-compose.yml (PROVIDED)
